# Camera MoE Implementation for GR00T N1d6

PI05 VLA ëª¨ë¸ì˜ ë©€í‹° ì¹´ë©”ë¼ ë¼ìš°í„°ë¥¼ GR00T N1d6ì— ì„±ê³µì ìœ¼ë¡œ ì ìš©í–ˆìŠµë‹ˆë‹¤.

## ğŸ“¦ êµ¬í˜„ íŒŒì¼

### 1. Camera Router ëª¨ë“ˆ
- **ìœ„ì¹˜**: `gr00t/model/modules/camera_router.py`
- **ë‚´ìš©**:
  - `CameraRouterConfig`: Router ì„¤ì •
  - `CameraRouter`: ë¼ìš°í„° ë„¤íŠ¸ì›Œí¬ (cam1 + prompt + state â†’ routing weights)
  - `CameraMoE`: Multi-camera fusion with soft gating

### 2. Config ì—…ë°ì´íŠ¸
- **ìœ„ì¹˜**: `gr00t/configs/model/gr00t_n1d6.py`
- **ì¶”ê°€ëœ ì„¤ì •**:
  ```python
  use_camera_moe: bool = False
  camera_router_hidden_dim: int = 512
  camera_router_temperature: float = 1.0
  camera_router_use_gumbel: bool = False
  camera_router_gumbel_temp: float = 1.0
  camera_routing_loss_weight: float = 0.1
  camera_router_use_attention_pooling: bool = True
  camera_router_use_learnable_scales: bool = True
  ```

### 3. Model í†µí•©
- **ìœ„ì¹˜**: `gr00t/model/gr00t_n1d6/gr00t_n1d6.py`
- **ë³€ê²½ì‚¬í•­**:
  - `Gr00tN1d6.__init__()`: Camera MoE ì´ˆê¸°í™”
  - `forward()`: Multi-camera ì§€ì› ë° routing loss ê³„ì‚°
  - `get_action()`: Inferenceì—ì„œ multi-camera ì§€ì›
  - `_forward_with_camera_moe()`: Multi-camera backbone ì²˜ë¦¬

### 4. ë¬¸ì„œ
- **ì‚¬ìš© ê°€ì´ë“œ**: `gr00t/model/modules/CAMERA_MOE_GR00T_N1D6.md`
- **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**: `test_camera_moe_integration.py`

---

## ğŸ”§ ì£¼ìš” ì°¨ì´ì : PI05 vs GR00T

| í•­ëª© | PI05 | GR00T N1d6 |
|------|------|------------|
| Base Camera | cam2 (Wrist) | cam1 (L515/External) |
| Auxiliary 1 | cam1 (L515) | cam2 (Left Wrist) |
| Auxiliary 2 | cam3 (Thermal) | cam3 (Right Wrist) |
| Router Input | cam2 + prompt + state | cam1 + prompt + state |
| Backbone | PaliGemma | Eagle-Block2A-2B-v2 |

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. Config ì„¤ì •

```python
from gr00t.configs.model.gr00t_n1d6 import Gr00tN1d6Config

config = Gr00tN1d6Config(
    model_name="nvidia/Eagle-Block2A-2B-v2",
    use_camera_moe=True,  # Camera MoE í™œì„±í™”
    camera_router_hidden_dim=512,
    camera_routing_loss_weight=0.1,
    camera_router_use_attention_pooling=True,
    camera_router_use_learnable_scales=True,
)
```

### 2. ëª¨ë¸ ìƒì„±

```python
from gr00t.model.gr00t_n1d6.gr00t_n1d6 import Gr00tN1d6

model = Gr00tN1d6(config)
```

### 3. Multi-Camera ì…ë ¥ í˜•ì‹

```python
inputs = {
    # Camera 1 (Base - L515/External, í•„ìˆ˜)
    "cam1_pixel_values": cam1_images,
    "cam1_input_ids": cam1_text,
    "cam1_attention_mask": cam1_mask,
    
    # Camera 2 (Left Wrist, ì„ íƒ)
    "cam2_pixel_values": cam2_images,
    "cam2_input_ids": cam2_text,
    "cam2_attention_mask": cam2_mask,
    
    # Camera 3 (Right Wrist, ì„ íƒ)
    "cam3_pixel_values": cam3_images,
    "cam3_input_ids": cam3_text,
    "cam3_attention_mask": cam3_mask,
    
    # State and Action
    "state": robot_state,
    "action": actions,
    "embodiment_id": embodiment_ids,
    "action_mask": action_mask,
    
    # Ground truth labels (training only)
    "cam2_activate": cam2_labels,  # [batch] binary
    "cam3_activate": cam3_labels,  # [batch] binary
}
```

### 4. Training

```python
outputs = model(inputs)

total_loss = outputs["loss"]  # action_loss + routing_loss
routing_weights = outputs["routing_weights"]  # [batch, 2]

print(f"Routing: Cam2={routing_weights[:, 0].mean():.3f}, "
      f"Cam3={routing_weights[:, 1].mean():.3f}")
```

### 5. Inference

```python
with torch.no_grad():
    outputs = model.get_action(inputs)
    actions = outputs["action"]
    routing_weights = outputs["routing_weights"]
```

---

## âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼

```bash
cd /home/choiyj/Isaac-GR00T
source .venv/bin/activate
python test_camera_moe_integration.py
```

**ê²°ê³¼**:
```
âœ“ All tests passed successfully!

Summary:
  1. CameraRouterConfig âœ“
  2. CameraMoE module âœ“
  3. GR00T N1d6 integration âœ“
  4. Backward compatibility âœ“
  5. Multi-camera input format âœ“
```

---

## ğŸ”„ Backward Compatibility

Camera MoEë¥¼ ë¹„í™œì„±í™”í•˜ë©´ ê¸°ì¡´ ì½”ë“œê°€ ê·¸ëŒ€ë¡œ ì‘ë™í•©ë‹ˆë‹¤:

```python
config = Gr00tN1d6Config(
    use_camera_moe=False,  # ê¸°ë³¸ê°’
)

model = Gr00tN1d6(config)

# ê¸°ì¡´ ë‹¨ì¼ ì¹´ë©”ë¼ ì…ë ¥ ì‚¬ìš©
outputs = model(single_camera_inputs)
```

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **ìƒì„¸ ì‚¬ìš© ê°€ì´ë“œ**: [CAMERA_MOE_GR00T_N1D6.md](gr00t/model/modules/CAMERA_MOE_GR00T_N1D6.md)
- **ì›ë³¸ PI05 ë¬¸ì„œ**: [CAMERA_MOE_ARCHITECTURE.md](gr00t/model/modules/CAMERA_MOE_ARCHITECTURE.md)

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **Pretrained Eagle weights ë¡œë“œ** í›„ full model test
2. **Real dataë¡œ training** ë° routing loss ëª¨ë‹ˆí„°ë§
3. **Multi-camera taskì—ì„œ evaluation**
4. **Hyperparameter tuning** (router_hidden_dim, routing_loss_weight ë“±)

---

## ğŸ“ êµ¬í˜„ ìƒì„¸

### Router Architecture

```
Input: cam1_features (pooled) + prompt (attention-pooled) + state
  â†“
Linear(embed_dim*2 + state_dim â†’ 512) + ReLU
  â†“
Linear(512 â†’ 256) + ReLU
  â†“
Linear(256 â†’ 2) â†’ Logits
  â†“
Softmax / Gumbel-Softmax â†’ Routing Weights [batch, 2]
```

### Feature Fusion

```
cam1_tokens (always included)
cam2_gated = Î³_cam2 âŠ™ (w_cam2 âŠ™ cam2_tokens)
cam3_gated = Î³_cam3 âŠ™ (w_cam3 âŠ™ cam3_tokens)
  â†“
concat([cam1_tokens, cam2_gated, cam3_gated], dim=-1)
  â†“
Linear(3*embed_dim â†’ embed_dim) â†’ Fused Features
```

### Routing Loss (Focal Loss)

```python
p_t = routing_weights[target_camera]
focal_weight = (1 - p_t)^gamma
loss = -alpha * focal_weight * log(p_t)
```

**íŒŒë¼ë¯¸í„°**:
- `alpha = 0.25`: Positive/negative balance
- `gamma = 2.0`: Focusing parameter (hard examples)

---

## ğŸ› Troubleshooting

### Q: "Camera MoE enabled but no multi-camera inputs found"
**A**: ì…ë ¥ ë°ì´í„°ì— `cam1_*`, `cam2_*`, `cam3_*` prefix ì¶”ê°€ ë˜ëŠ” `use_camera_moe=False`

### Q: Routing lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ
**A**: 
1. Ground truth labels (`cam2_activate`, `cam3_activate`) í™•ì¸
2. `camera_routing_loss_weight` ì¦ê°€ (0.1 â†’ 0.2)

### Q: Action prediction ì„±ëŠ¥ ì €í•˜
**A**: `camera_routing_loss_weight` ê°ì†Œ (0.1 â†’ 0.05)

---

**êµ¬í˜„ ì™„ë£Œ**: 2026ë…„ 1ì›” 15ì¼  
**í…ŒìŠ¤íŠ¸**: âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼  
**ë¬¸ì„œ**: âœ… ì™„ì„±
